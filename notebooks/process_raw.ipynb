{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory Association in Historical Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the root of the project\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "ROOT = Path(os.getcwd()).parent\n",
    "while not ROOT.joinpath(\".git\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "# add the root to the python path\n",
    "import sys\n",
    "\n",
    "sys.path.append(str(ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from src.frenet import SplineLane\n",
    "from src.radar import BasicRadar\n",
    "from src.polars_utils import build_if_when\n",
    "\n",
    "# load the environment variables\n",
    "dotenv.load_dotenv(ROOT.joinpath(\".env\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start & End Time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from pytz import timezone\n",
    "\n",
    "\n",
    "start_time = datetime(2023, 3, 13, 6, 0, 0, tzinfo=timezone(\"US/Central\"))\n",
    "end_time = datetime(2023, 3, 13, 12, 0, 0, tzinfo=timezone(\"US/Central\"))\n",
    "\n",
    "# convert to utc\n",
    "start_time_utc = start_time.astimezone(timezone(\"UTC\"))\n",
    "end_time_utc = end_time.astimezone(timezone(\"UTC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RADAR_DIR = Path(\"/DOECV2X/Radar\") / \"all_working\"\n",
    "print(RADAR_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Radar Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to a file for speed\n",
    "tmp_file = ROOT / \"tmp\" / f\"{RADAR_DIR.stem}.parquet\"\n",
    "tmp_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "radar_df = pl.scan_parquet(tmp_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.radar import Filtering\n",
    "\n",
    "f = Filtering(\n",
    "    network_boundary_path=ROOT / \"geo_data\" / \"network_outline.geojson\",\n",
    "    radar_location_path=ROOT / \"geo_data\" / \"calibrated_origins.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(radar_df, pl.DataFrame):\n",
    "    radar_df = radar_df.lazy()\n",
    "\n",
    "radar_df = (\n",
    "    radar_df\n",
    "    # .filter(\n",
    "    #     (\n",
    "    #         (pl.col(\"epoch_time\").cast(pl.Float64()) / 1000)\n",
    "    #         > start_time_utc.timestamp()\n",
    "    #     )\n",
    "    #     & (\n",
    "    #         (pl.col(\"epoch_time\").cast(pl.Float64()) / 1000)\n",
    "    #         < end_time_utc.timestamp()\n",
    "    #     )\n",
    "    # )\n",
    "    # .collect(streaming=True)\n",
    "    # .lazy()\n",
    "    # create the object_id column\n",
    "    .pipe(f.create_object_id)\n",
    "    # .pipe(f.correct_center)\n",
    "    # sort by object_id and epoch_time\n",
    "    .sort(by=[\"object_id\", \"epoch_time\"])\n",
    "    .set_sorted([\"object_id\", \"epoch_time\"])\n",
    "    # filter out vehicles that don't trave some minimum distance (takes care of radar noise)\n",
    "    # .pipe(f.filter_short_trajectories, minimum_distance_m=10, minimum_duration_s=2)\n",
    "    # resample to 10 Hz\n",
    "    .pipe(f.resample, 100)\n",
    "    # smooth the values during stop events. This is allowed because there is no\n",
    "    # .pipe(f.fix_stop_param_walk)\n",
    "    # # fix when the radar is outputs the same data for multiple frames\n",
    "    .pipe(f.fix_duplicate_positions)\n",
    "    # clip the end of trajectories where the velocity is constant\n",
    "    # .pipe(f.clip_trajectory_end)\n",
    "    .pipe(f.set_timezone, timezone_=\"UTC\")\n",
    "    # .pipe(f.add_cst_timezone)\n",
    "    # filter just the first 12 hours of data\n",
    "    # .pipe(f.crop_radius, 400)\n",
    "    .pipe(f.rotate_radars)\n",
    "    .pipe(f.update_origin)\n",
    "    .pipe(f.rotate_heading)\n",
    "    # .collect(streaming=True)\n",
    "    # .pipe(f.radar_to_latlon)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "radar_df.filter(\n",
    "    pl.col('epoch_time').is_between(\n",
    "        pl.col('epoch_time').min() + timedelta(minutes=45),\n",
    "        pl.col('epoch_time').min() + timedelta(minutes=50)\n",
    "    )\n",
    ").pipe(\n",
    "    f.radar_to_latlon\n",
    ").select(['ip', 'object_id', 'lat', 'lon', 'epoch_time']).write_csv(\n",
    "    'test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Lane Centerlines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Frenet Centerlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.frenet import SplineLane\n",
    "from src.geometry import load_centerlines\n",
    "import numpy as np\n",
    "\n",
    "spline_lanes = [\n",
    "    SplineLane(\n",
    "        name=lane,\n",
    "        centerline=np.c_[l_df.geometry.x, l_df.geometry.y],\n",
    "        width=3.7,\n",
    "        crs=l_df.crs,\n",
    "    )\n",
    "    .fit(\n",
    "        s=2,\n",
    "        k=2,\n",
    "    )\n",
    "    .interpolate(ds=0.1)\n",
    "    for lane, l_df in load_centerlines(\n",
    "        ROOT / \"geo_data\" / \"centerlines.geojson\"\n",
    "    ).groupby(\"lane\")\n",
    "    if lane in ['EBL1', 'WBL1']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map the Radar Points to the Centerlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipelines.snap_lanes import pipe_lanes, pipe_lanebounce_fix\n",
    "\n",
    "radar_df = radar_df.pipe(\n",
    "    pipe_lanes, \n",
    "    radar_obj=BasicRadar, \n",
    "    spline_lanes=spline_lanes, \n",
    "    # 10 meter matching threshold (widest lane is 3.7 meters)\n",
    "    distance_threshold=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_df.filter(\n",
    "    pl.col('lane') == 'EBL1'\n",
    ")['min_d'].sample(100_000).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_df.filter(\n",
    "    pl.col('lane') == 'WBL1'\n",
    ")['min_d'].sample(100_000).to_pandas().hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_df['epoch_time'].min(), radar_df['epoch_time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_file = ROOT / \"notebooks\" / \"clean_workflow\" / \"data\" / f\"{RADAR_DIR.stem}_processed.parquet\"\n",
    "\n",
    "\n",
    "radar_df.filter(pl.col('lane').is_not_null()).filter(\n",
    "    pl.col('min_d').is_between(-6, 10)\n",
    ").write_parquet(\n",
    "    processed_file.parent / f\"{processed_file.stem}_1Lane.parquet\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
